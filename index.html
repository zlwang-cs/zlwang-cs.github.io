<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zilong Wang</title>
  <meta name="author" content="Zilong Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" type="image/x-icon" href="images/ucsd.ico">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400&display=swap" rel="stylesheet">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-H9V8CNLGZS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-H9V8CNLGZS');
  </script>

  <!-- Highlight tag CSS -->
  <style>
    .highlight-tag {
      color: #d14;       /* elegant academic red */
      font-weight: 600;
    }
    .paper-summary {
      margin: 0;
      padding: 0;
      color: #777;
      font-size: 1em;
      font-weight: 400;
      line-height: 1.3;
      letter-spacing: 0.01em;
      font-style: italic;
    }
    .highlighted-word {
      background-color: #ffffda;
      padding: 2px 4px;
      border-radius: 4px;
    }

    .paper-entry {
      padding: 8px;
      width: 95%;
      margin-bottom: 10px;     /* adjust value as you like */
      display: block;          /* required for margin to work inside <td> */
    }

    .paper-entry.highlighted {
      background-color: #ffffda;
      border-radius: 6px;      /* optional */
    }

  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- Header block -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Zilong Wang
                  </p>

                  <p>
                    I am a Research Scientist at Google DeepMind. I completed my Ph.D. in Computer Science at 
                    <a href="https://cse.ucsd.edu/" target="_blank">UC San Diego</a> in 2025, 
                    advised by <a href="https://shangjingbo1226.github.io/" target="_blank">Professor Jingbo Shang</a>. 
                    Before that, I received my B.S. in Computer Science from 
                    <a href="https://english.pku.edu.cn" target="_blank">Peking University</a> in 2020, 
                    where I worked with <a href="https://wanxiaojun.github.io/" target="_blank">Professor Xiaojun Wan</a>.
                  </p>

                  <p>
                    My research focuses on building effective and reliable LLM agents for code generation. 
                    If you'd like to discuss research—or just chat—feel free to reach out at
                    <span style="padding-left: 3px; font-family: 'JetBrains Mono', monospace; color: #555;">
                      zlwang.ucsd at gmail dot com
                    </span>
                    .
                  </p>

                  <p style="text-align:center">
                    <a href="https://x.com/zlwang_cs">X</a>&nbsp;/&nbsp;
                    <a href="https://github.com/zlwang-cs">Github</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=S_wQccsAAAAJ">Scholar</a>&nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/zilong-wang-742436171/">Linkedin</a>
                  </p>
                </td>

                <td style="padding:2.5%;width:40%;max-width:40%;">
                  <img style="width:100%;max-width:100%;" alt="profile photo" src="images/profile.jpg">
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications header -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:8px;width:100%;vertical-align:middle">
                  <h2>Publications</h2>
                  <p>
                    Some papers are <span class="highlighted-word">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications list -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- Small Proxies (newest arXiv: 2510) -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2510.01427">
                  <span class="papertitle">A Tale of LLMs and Induced Small Proxies: Scalable Agents for Knowledge Mining</span>
                </a>
                <br>
                Sipeng Zhang, Longfei Yun, <strong>Zilong Wang</strong>, Jingbo Shang, Letian Peng
                <br>
                <em>Preprint</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2510.01427">arXiv</a>
              </td></tr>
            
              <!-- Multi-objective Alignment -->
              <tr><td class="paper-entry highlighted">
                <p class="paper-summary">[Adaptive weighting for <u><strong>multi-objective RL</strong></u>, achiving <u><strong>SOTA for all rewards</strong></u>]</p>
                <a href="https://arxiv.org/abs/2509.11452">
                  <span class="papertitle">Learning to Optimize Multi-objective Alignment through Dynamic Reward Weighting</span>
                </a>
                <br>
                Yining Lu, <strong>Zilong Wang**</strong>, Shiyang Li, Xin Liu, Changlong Yu, Qingyu Yin, Zhan Shi, Zixuan Zhang, Meng Jiang (** corresponding author)
                <br>
                <em>Preprint</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2509.11452">arXiv</a>
              </td></tr>
            
              <!-- ReaL -->
              <tr><td class="paper-entry highlighted">
                <p class="paper-summary">[Build <u><strong>effective & reliable coding LLMs</strong></u> with hybrid rewards: program analysis + unit tests]</p>
                <a href="https://arxiv.org/abs/2505.22704">
                  <span class="papertitle">Training Language Models to Generate Quality Code with Program Analysis Feedback</span>
                </a>
                <br>
                Feng Yao*, <strong>Zilong Wang*</strong>, Liyuan Liu, Junxia Cui, Li Zhong, Xiaohan Fu, Haohui Mai, Vish Krishnan, Jianfeng Gao, Jingbo Shang (* equal contribution)
                <br>
                <em>NeurIPS</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2505.22704">arXiv</a> /
                <a href="https://github.com/yaof20/ReaL">code</a>
              </td></tr>
            
              <!-- RRO -->
              <tr><td class="paper-entry highlighted">
                <p class="paper-summary">[Rising-reward trajectory mining for <u><strong>efficient process-reward data collection</strong></u>]</p>
                <a href="https://arxiv.org/abs/2505.20737">
                  <span class="papertitle">RRO: LLM Agent Optimization Through Rising Reward Trajectories</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Jingfeng Yang, Sreyashi Nag, Samarth Varshney, Xianfeng Tang, Haoming Jiang, Jingbo Shang, Sheikh Muhammad Sarwar
                <br>
                <em>COLM</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2505.20737">arXiv</a>
              </td></tr>
            
              <!-- TableRAG -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2410.04739">
                  <span class="papertitle">TableRAG: Million-Token Table Understanding with Language Models</span>
                </a>
                <br>
                Si-An Chen, Lesly Miculicich, Julian Martin Eisenschlos, Zifeng Wang, <strong>Zilong Wang</strong>, Yanfei Chen, Yasuhisa Fujii, Hsuan-Tien Lin, Chen-Yu Lee, Tomas Pfister
                <br>
                <em>NeurIPS</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2410.04739">arXiv</a>
              </td></tr>
            
              <!-- OfficeBench -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2407.19056">
                  <span class="papertitle">OfficeBench: Benchmarking Language Agents across Multiple Applications for Office Automation</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Yuedong Cui, Li Zhong, Zimin Zhang, Da Yin, Bill Yuchen Lin, Jingbo Shang
                <br>
                <em>Preprint</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2407.19056">arXiv</a>
              </td></tr>
            
              <!-- Speculative RAG -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2407.08223">
                  <span class="papertitle">Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo Shang, Chen-Yu Lee, Tomas Pfister
                <br>
                <em>ICLR</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2407.08223">arXiv</a> /
                <a class="highlight-tag" href="https://research.google/blog/speculative-rag-enhancing-retrieval-augmented-generation-through-drafting/">
                  featured: Google Research Blog
                </a>
              </td></tr>
            
              <!-- Debug like a Human -->
              <tr><td class="paper-entry highlighted">
                <p class="paper-summary">[<u><strong>Runtime-verified, stepwise reasoning (via execution trace)</strong></u> for precise LLM-based code debugging]</p>
                <a href="https://arxiv.org/abs/2402.16906">
                  <span class="papertitle">Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step</span>
                </a>
                <a href="https://github.com/FloridSleeves/LLMDebugger">
                  <img src="https://img.shields.io/github/stars/FloridSleeves/LLMDebugger?style=social"
                       style="height:16px;vertical-align:middle;">
                </a>
                <br>
                Li Zhong, <strong>Zilong Wang</strong>, Jingbo Shang (** corresponding author)
                <br>
                <em>ACL</em> Findings, 2024
                <br>
                <a href="https://arxiv.org/abs/2402.16906">arXiv</a> /
                <a href="https://github.com/FloridSleeves/LLMDebugger">code</a> /
                <a class="highlight-tag" href="https://www.marktechpost.com/2024/03/09/can-llms-debug-programs-like-human-developers-ucsd-researchers-introduce-ldb-a-machine-learning-based-debugging-framework-with-llms/">
                  featured: MarkTechPost
                </a> /
                <a class="highlight-tag" href="https://event.baai.ac.cn/activities/770">
                  talk: BAAI
                </a> /
                <a class="highlight-tag" href="https://paperswithcode.com/sota/code-generation-on-humaneval">
                  sota: HumanEval 98.2%
                </a>
              </td></tr>
            
              <!-- Answer is All You Need -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2402.09642">
                  <span class="papertitle">Answer is All You Need: Instruction-following Text Embedding via Answering the Question</span>
                </a>
                <br>
                Letian Peng, Yuwei Zhang, <strong>Zilong Wang</strong>, Jayanth Srinivasa, Gaowen Liu, Zihan Wang, Jingbo Shang
                <br>
                <em>NAACL</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2402.09642">arXiv</a> /
                <a href="https://github.com/zhang-yu-wei/InBedder">code</a>
              </td></tr>
            
              <!-- Chain-of-Table -->
              <tr><td class="paper-entry highlighted">
                <p class="paper-summary">[Iterative table transformation powering the <u><strong>first tabular reasoning agent</strong></u>]</p>
                <a href="https://arxiv.org/abs/2401.04398">
                  <span class="papertitle">Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Tomas Pfister
                <br>
                <em>ICLR</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2401.04398">arXiv</a> /
                <a href="https://github.com/google-research/chain-of-table">code</a> /
                <a class="highlight-tag" href="https://research.google/blog/chain-of-table-evolving-tables-in-the-reasoning-chain-for-table-understanding/">
                  featured: Google Research Blog
                </a>
              </td></tr>
            
              <!-- LMDX -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2309.10952">
                  <span class="papertitle">LMDX: Language Model-based Document Information Extraction and Localization</span>
                </a>
                <br>
                Vincent Perot, Kai Kang, Florian Luisier, Guolong Su, Xiaoyu Sun, Ramya Sree Boppana, <strong>Zilong Wang</strong>, Jiaqi Mu, Hao Zhang, Nan Hua
                <br>
                <em>ACL</em> Findings, 2024
                <br>
                <a href="https://arxiv.org/abs/2309.10952">arXiv</a>
              </td></tr>
            
              <!-- Robustness & Reliability -->
              <tr><td class="paper-entry highlighted">
                <p class="paper-summary">[<u><strong>Real-world API reliability evaluation</strong></u> of coding LLMs <u><strong>at scale</strong></u> (LLM wasn't as good as StackOverflow at least in 2024)]</p>
                <a href="https://arxiv.org/abs/2308.10335">
                  <span class="papertitle">Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability of Large Language Model Code Generation</span>
                </a>
                <br>
                Li Zhong, <strong>Zilong Wang</strong>
                <br>
                <em>AAAI</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2308.10335">arXiv</a> /
                <a href="https://github.com/FloridSleeves/RobustAPI">code</a> /
                <a class="highlight-tag" href="https://www.theregister.com/2023/08/29/ai_models_coding/">
                  featured: TheRegister
                </a>
              </td></tr>
            
              <!-- Few-shot GNN -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2305.14828">
                  <span class="papertitle">Towards Few-shot Entity Recognition in Document Images: A Graph Neural Network Approach Robust to Image Manipulation</span>
                </a>
                <br>
                Prashant Krishnan, <strong>Zilong Wang</strong>, Yangkun Wang, Jingbo Shang
                <br>
                <em>COLING</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2305.14828">arXiv</a>
              </td></tr>
            
              <!-- XML Path -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2305.13805">
                  <span class="papertitle">Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Jingbo Shang
                <br>
                <em>EMNLP</em> Findings, 2023
                <br>
                <a href="https://arxiv.org/abs/2305.13805">arXiv</a>
              </td></tr>
            
              <!-- VRDU -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2211.15421">
                  <span class="papertitle">VRDU: A Benchmark for Visually-rich Document Understanding</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Yichao Zhou, Wei Wei, Chen-Yu Lee, Sandeep Tata
                <br>
                <em>KDD</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2211.15421">arXiv</a> /
                <a href="https://github.com/google-research/google-research/tree/master/vrdu">code</a> /
                <a href="https://research.google/resources/datasets/visually-rich-document-understanding/">dataset</a>
              </td></tr>
            
              <!-- MGDoc -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2211.14958">
                  <span class="papertitle">MGDoc: Pre-training with Multi-granular Hierarchy for Document Image Understanding</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Jiuxiang Gu, Chris Tensmeyer, Nikolaos Barmpalios, Ani Nenkova, Tong Sun, Jingbo Shang, Vlad I. Morariu
                <br>
                <em>EMNLP</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2211.14958">arXiv</a>
              </td></tr>
            
              <!-- LASER -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2204.05819">
                  <span class="papertitle">Towards Few-shot Entity Recognition in Document Images: A Label-aware Sequence-to-Sequence Framework</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Jingbo Shang
                <br>
                <em>ACL</em> Findings, 2022
                <br>
                <a href="https://arxiv.org/abs/2204.05819">arXiv</a> /
                <a href="https://github.com/zlwang-cs/LASER-release">code</a>
              </td></tr>
            
              <!-- LayoutReader -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2108.11591">
                  <span class="papertitle">LayoutReader: Pre-training of Text and Layout for Reading Order Detection</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Yiheng Xu, Lei Cui, Jingbo Shang, Furu Wei
                <br>
                <em>EMNLP</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2108.11591">arXiv</a> /
                <a href="https://github.com/microsoft/unilm/tree/master/layoutreader">code</a>
              </td></tr>
            
              <!-- DocStruct -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2010.11685">
                  <span class="papertitle">DocStruct: A Multimodal Method to Extract Hierarchy Structure in Document for General Form Understanding</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Mingjie Zhan, Xuebo Liu, Ding Liang
                <br>
                <em>EMNLP</em> Findings, 2020
                <br>
                <a href="https://arxiv.org/abs/2010.11685">arXiv</a>
              </td></tr>
            
              <!-- Semantic Capacity -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2010.01898">
                  <span class="papertitle">Exploring Semantic Capacity of Terms</span>
                </a>
                <br>
                Jie Huang*, <strong>Zilong Wang*</strong>, Kevin Chang, Wen-Mei Hwu, Jinjun Xiong (* equal contribution)
                <br>
                <em>EMNLP</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/2010.01898">arXiv</a>
              </td></tr>
            
              <!-- TransModality (no arXiv originally, now with arXiv link) -->
              <tr><td class="paper-entry">
                <a href="https://arxiv.org/abs/2009.02902">
                  <span class="papertitle">TransModality: An End2End Fusion Method with Transformer for Multimodal Sentiment Analysis</span>
                </a>
                <br>
                <strong>Zilong Wang</strong>, Zhaohong Wan, Xiaojun Wan
                <br>
                <em>WWW</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/2009.02902">arXiv</a>
              </td></tr>
            
            </tbody>
          </table>

          <!-- Footer: Visitor Map and Template Credit -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:20px;">
            <tbody>
              <tr>
                <td style="padding:20px 10px;width:100%;text-align:center;vertical-align:middle;border-top:1px solid #eee;">
                  <div style="width:150px;margin:0 auto 8px auto;">
                    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=vaoSErHYKQca3pHxFxyj3cWdLSHP9-8DHno25BjCcuw&cl=ffffff&w=a"></script>
                  </div>
                  <p style="font-size:12px;margin:0;">
                    Last updated: November 2025 | Template by <a href="https://jonbarron.info/">Jon Barron</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>

</body>
</html>
